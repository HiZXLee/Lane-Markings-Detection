{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-18T10:35:51.831194Z","iopub.execute_input":"2021-12-18T10:35:51.831578Z","iopub.status.idle":"2021-12-18T10:35:59.781741Z","shell.execute_reply.started":"2021-12-18T10:35:51.83148Z","shell.execute_reply":"2021-12-18T10:35:59.780773Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\n\nimport skimage.transform\nimport datetime as dt\n\nfrom sklearn.model_selection import train_test_split\n\n#calculate time\nstart = dt.datetime.now()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-18T12:54:37.947799Z","iopub.execute_input":"2021-12-18T12:54:37.948222Z","iopub.status.idle":"2021-12-18T12:54:44.17227Z","shell.execute_reply.started":"2021-12-18T12:54:37.948107Z","shell.execute_reply":"2021-12-18T12:54:44.17155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initialize","metadata":{}},{"cell_type":"code","source":"img_width, img_height = 320, 320\nbatch_size = 12\nepochs = 2\nimg_channels=3\nprevCheckpoint = None\nroot = r'../input'\n","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:44.174127Z","iopub.execute_input":"2021-12-18T12:54:44.174417Z","iopub.status.idle":"2021-12-18T12:54:44.180054Z","shell.execute_reply.started":"2021-12-18T12:54:44.174356Z","shell.execute_reply":"2021-12-18T12:54:44.178963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= pd.read_csv(os.path.join(root, 'culanelist/list/train_gt.txt'), delim_whitespace=True, header=None)\n\n#This example is only training on driver_161_90 frames of the CULane \n\ndf = df[df[0].str.contains('driver_161_90')].reset_index(drop=True)\ndf[0]=df[0].replace({'/driver_161_90frame':os.path.join(root, 'culane/driver_161_90frame')}, regex=True)\ndf[1]=df[1].replace({'/laneseg_label_w16/driver_161_90frame':os.path.join(root, 'culane/driver_161_90frame_labels')}, regex=True)\n\n#split for train and validation set\n\ntrain_df, valid_df = train_test_split(df, test_size=0.1, random_state=18)\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:44.181187Z","iopub.execute_input":"2021-12-18T12:54:44.181425Z","iopub.status.idle":"2021-12-18T12:54:44.70948Z","shell.execute_reply.started":"2021-12-18T12:54:44.181393Z","shell.execute_reply":"2021-12-18T12:54:44.708779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = train_df[0].copy()\ntrain_dir_gt = train_df[1].copy()\n\nvalid_dir = valid_df[0].copy()\nvalid_dir_gt = valid_df[1].copy()\n\nn_train_samples = len(train_dir)\nn_valid_samples = len(valid_dir)\n\nprint('Training samples: {}'.format(n_train_samples))\nprint('Valid samples: {}'.format(n_valid_samples))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:44.710675Z","iopub.execute_input":"2021-12-18T12:54:44.710924Z","iopub.status.idle":"2021-12-18T12:54:44.720757Z","shell.execute_reply.started":"2021-12-18T12:54:44.710892Z","shell.execute_reply":"2021-12-18T12:54:44.720059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generator","metadata":{}},{"cell_type":"code","source":"# Train data generator\n\ndef train_generator():\n    while True:\n        for start in range(0, n_train_samples, batch_size):\n            x_batch = []\n            y_batch = []\n            end = min(start + batch_size, n_train_samples)\n            for img_path in range(start, end):\n                img = cv2.imread(train_dir[img_path])\n                \n                img = skimage.transform.resize(img, (img_height, img_width), preserve_range=True, \n                                               anti_aliasing=False, order=0)\n                \n                x_batch.append(img)\n\n                img = cv2.imread(train_dir_gt[img_path])\n                img = skimage.transform.resize(img, (img_height, img_width,1), preserve_range=True, \n                                               anti_aliasing=False,  order=0)\n          \n                y_batch.append(img)\n                \n            y_batch = tf.keras.utils.to_categorical(y_batch, num_classes=5)\n\n            yield (np.array(x_batch), np.array(y_batch) )","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:44.723275Z","iopub.execute_input":"2021-12-18T12:54:44.723747Z","iopub.status.idle":"2021-12-18T12:54:44.732658Z","shell.execute_reply.started":"2021-12-18T12:54:44.723709Z","shell.execute_reply":"2021-12-18T12:54:44.731974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_generator():\n    while True:\n        for start in range(0, n_valid_samples, batch_size):\n            \n            x_batch = []\n            y_batch = []\n            \n            end = min(start + batch_size, n_valid_samples)\n            for img_path in range(start, end):\n                img = cv2.imread(valid_dir[img_path])\n                \n                img = skimage.transform.resize(img, (img_height, img_width), preserve_range=True, \n                                               anti_aliasing=False, order=0)\n                \n                x_batch.append(img)\n\n                img = cv2.imread(valid_dir_gt[img_path])\n                img = skimage.transform.resize(img, (img_height, img_width,1), preserve_range=True, \n                                               anti_aliasing=False, order=0)\n             \n                y_batch.append(img)\n\n                \n            y_batch = tf.keras.utils.to_categorical(y_batch, num_classes=5)\n\n            \n            yield (np.array(x_batch), np.array(y_batch))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:44.734078Z","iopub.execute_input":"2021-12-18T12:54:44.734385Z","iopub.status.idle":"2021-12-18T12:54:44.745662Z","shell.execute_reply.started":"2021-12-18T12:54:44.734327Z","shell.execute_reply":"2021-12-18T12:54:44.744741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics and Loss Function","metadata":{}},{"cell_type":"code","source":"def precision(y_true, y_pred, numLabels=5):\n    \n    y_true = K.permute_dimensions(y_true, (3,1,2,0))\n    y_pred = K.permute_dimensions(y_pred, (3,1,2,0))\n\n    y_true_current = K.batch_flatten(y_true)\n    y_pred_current = K.batch_flatten(y_pred)\n\n    true_pos = K.sum(y_true_current*y_pred_current,1)\n    false_neg = K.sum(y_true_current * (1-y_pred_current), 1)\n    false_pos = K.sum((1-y_true_current)*y_pred_current, 1)\n    precision = true_pos/(true_pos+false_pos)\n    \n    return precision\n\ndef recall(y_true, y_pred, numLabels=5):\n    \n    y_true = K.permute_dimensions(y_true, (3,1,2,0))\n    y_pred = K.permute_dimensions(y_pred, (3,1,2,0))\n\n    y_true_current = K.batch_flatten(y_true)\n    y_pred_current = K.batch_flatten(y_pred)\n    true_pos = K.sum(y_true_current*y_pred_current,1)\n    false_neg = K.sum(y_true_current * (1-y_pred_current), 1)\n    false_pos = K.sum((1-y_true_current)*y_pred_current, 1)\n\n    recall = true_pos/(true_pos+false_neg)\n    \n    return recall\n\n\ndef f1_score(y_true, y_pred, numLabels=5):\n\n    precisions = K.sum(precision(y_true, y_pred))/numLabels\n    recalls = K.sum(recall(y_true, y_pred))/numLabels\n\n    f1_score = 2*((precisions*recalls)/(precisions+recalls+K.epsilon()))\n    return f1_score","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:44.748639Z","iopub.execute_input":"2021-12-18T12:54:44.748832Z","iopub.status.idle":"2021-12-18T12:54:44.761309Z","shell.execute_reply.started":"2021-12-18T12:54:44.74881Z","shell.execute_reply":"2021-12-18T12:54:44.760433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference: https://github.com/nabsabraham/focal-tversky-unet/issues/3\ndef class_tversky(y_true, y_pred):\n    smooth = 1\n\n    y_true = K.permute_dimensions(y_true, (3,1,2,0))\n    y_pred = K.permute_dimensions(y_pred, (3,1,2,0))\n\n    y_true_pos = K.batch_flatten(y_true)\n    y_pred_pos = K.batch_flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos, 1)\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos), 1)\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos, 1)\n    alpha = 0.25\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\n# channels sensitive loss function\ndef focal_tversky_loss_c(y_true,y_pred):\n    pt_1 = class_tversky(y_true, y_pred)\n    gamma = 0.75\n    return K.sum(K.pow((1-pt_1), gamma))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:44.764732Z","iopub.execute_input":"2021-12-18T12:54:44.764921Z","iopub.status.idle":"2021-12-18T12:54:44.774605Z","shell.execute_reply.started":"2021-12-18T12:54:44.764893Z","shell.execute_reply":"2021-12-18T12:54:44.773781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UNet Model","metadata":{}},{"cell_type":"code","source":"def Conv2D_layer(prev_layer, f, k=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same'):\n    return layers.Conv2D(f, k, activation=activation, kernel_initializer=kernel_initializer, padding=padding)(prev_layer)\n\ndef down_block(in_layer, f, dropout=None, pool=True):\n    \n    c = Conv2D_layer(prev_layer=in_layer, f=f)\n    \n    if dropout is not None:\n        c = layers.SpatialDropout2D(dropout)(c)\n        \n    c = Conv2D_layer(prev_layer=c, f=f)\n    c = layers.BatchNormalization()(c)\n    \n    if pool == True:\n        p = layers.MaxPooling2D((2,2))(c)\n    \n        return c, p\n    else:\n        return c\n\ndef up_block(in_layer, concat_layer, f, dropout=None):\n\n    u = layers.Conv2DTranspose(f, (2, 2), strides=(2, 2), padding='same')(in_layer)\n    u = layers.concatenate([u, concat_layer])\n    c = Conv2D_layer(prev_layer=u, f=f)\n    \n    if dropout is not None:\n        c = layers.SpatialDropout2D(0.4)(c)\n        \n    c = Conv2D_layer(prev_layer=c, f=f)\n    c = layers.BatchNormalization()(c)\n    \n    return c","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:44.777777Z","iopub.execute_input":"2021-12-18T12:54:44.777963Z","iopub.status.idle":"2021-12-18T12:54:44.789851Z","shell.execute_reply.started":"2021-12-18T12:54:44.777941Z","shell.execute_reply":"2021-12-18T12:54:44.789114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninputs = layers.Input((img_height,img_width, img_channels))\n\ns = layers.Lambda(lambda x: x / 255)(inputs)\n\nc1, p1 = down_block(in_layer=s, f=16, dropout=0.1)\n\nc2, p2 = down_block(in_layer=p1, f=32, dropout=0.1)\n\nc3, p3 = down_block(in_layer=p2, f=64, dropout=0.2)\n\nc4, p4 = down_block(in_layer=p3, f=128, dropout=0.3)\n\nc5, p5 = down_block(in_layer=p4, f=256, dropout=0.4)\n \nc6 = down_block(in_layer=p5, f=512, dropout=0.5, pool=False)\n\n##############################################################################################\n\nc7 = up_block(in_layer=c6, concat_layer=c5, f=256, dropout=0.4)\n\nc8 = up_block(in_layer=c7, concat_layer=c4, f=128, dropout=0.3)\n \nc9 = up_block(in_layer=c8, concat_layer=c3, f=64, dropout=0.2)\n\nc10 = up_block(in_layer=c9, concat_layer=c2, f=32, dropout=0.1)\n\nc11 = up_block(in_layer=c10, concat_layer=c1, f=16, dropout=0.1)\n\n# output = layers.Conv2D(5, (1, 1), activation='sigmoid', name='output')(c11)\n\noutput = Conv2D_layer(prev_layer=c11, f=5, k=(1, 1), activation='sigmoid')\n \nmodel = tf.keras.Model(inputs=[inputs], outputs=[output])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5, clipnorm=1.0),loss=focal_tversky_loss_c, metrics=[tf.keras.metrics.CategoricalAccuracy(), precision, recall, f1_score])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:44.790855Z","iopub.execute_input":"2021-12-18T12:54:44.791405Z","iopub.status.idle":"2021-12-18T12:54:47.546545Z","shell.execute_reply.started":"2021-12-18T12:54:44.791348Z","shell.execute_reply":"2021-12-18T12:54:47.545845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"#Model CheckPoint\n\ncheckpointer = tf.keras.callbacks.ModelCheckpoint('model_for_CuLane_UNET.h5', verbose=1, save_best_only=True)\n\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n    tf.keras.callbacks.CSVLogger(\"history.csv\", append=True),\n    checkpointer\n] ","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:47.547833Z","iopub.execute_input":"2021-12-18T12:54:47.548081Z","iopub.status.idle":"2021-12-18T12:54:47.554603Z","shell.execute_reply.started":"2021-12-18T12:54:47.548046Z","shell.execute_reply":"2021-12-18T12:54:47.553226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if prevCheckpoint is not None:\n    model.load_weights(prevCheckpoint)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:47.556405Z","iopub.execute_input":"2021-12-18T12:54:47.55672Z","iopub.status.idle":"2021-12-18T12:54:47.566422Z","shell.execute_reply.started":"2021-12-18T12:54:47.556683Z","shell.execute_reply":"2021-12-18T12:54:47.565699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    train_generator(),\n    steps_per_epoch= n_train_samples // batch_size,\n    epochs= epochs,\n    validation_data= valid_generator(),\n    validation_steps = n_valid_samples // batch_size,\n    callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:54:47.567802Z","iopub.execute_input":"2021-12-18T12:54:47.56805Z","iopub.status.idle":"2021-12-18T12:55:33.321651Z","shell.execute_reply.started":"2021-12-18T12:54:47.568017Z","shell.execute_reply":"2021-12-18T12:55:33.316909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('Unet_1_epoch.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:55:33.322542Z","iopub.status.idle":"2021-12-18T12:55:33.322926Z","shell.execute_reply.started":"2021-12-18T12:55:33.322725Z","shell.execute_reply":"2021-12-18T12:55:33.322745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"end = dt.datetime.now()\nprint('Total time: ' + str(end-start))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T12:55:33.326754Z","iopub.status.idle":"2021-12-18T12:55:33.327358Z","shell.execute_reply.started":"2021-12-18T12:55:33.327117Z","shell.execute_reply":"2021-12-18T12:55:33.327149Z"},"trusted":true},"execution_count":null,"outputs":[]}]}